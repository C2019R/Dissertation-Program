{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas and dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Pre-Processed Dataset.csv\")\n",
    "\n",
    "#Select predictor columns\n",
    "cols = ['CourseViewed', 'ReasonForStudy', 'LearnerType', 'StudyHours', 'PreviousEducation', 'AgeRange']\n",
    "data = df[cols]\n",
    "#Assign the SubjectArea column as target\n",
    "target = df['SubjectArea']\n",
    "\n",
    "#Import the necessary module\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Split data set into train and test sets data_train, data_test, target_train, \n",
    "target_test = train_test_split(data,target, test_size = 0.30, random_state = 10)\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size= 0.30, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Unbalanced Accuracy Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of the type SVC\n",
    "svc_model = SVC(random_state=0)\n",
    "#Train the model using the training sets\n",
    "svc_model.fit(data_train, target_train)\n",
    "#Predict the response for test dataset\n",
    "pred = svc_model.predict(data_test)\n",
    "#print the accuracy scores of the model\n",
    "print(\"SVC accuracy: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type GradientBoostingClassifier\n",
    "gbc_model = GradientBoostingClassifier(random_state=0)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = gbc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"GradientBoostingClassifier accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type DecisionTreeClassifier\n",
    "dtc_model = DecisionTreeClassifier(random_state=0)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = dtc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"DecisionTreeClassifier accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type LinearSVC\n",
    "rfc_model = RandomForestClassifier(random_state=0)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = rfc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"RandomForestClassifier accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type LogisticRegression\n",
    "lr_model = LogisticRegression(random_state=0)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = lr_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"LogisticRegression accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type LinearSVC\n",
    "linearsvc_model = LinearSVC(random_state=0)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = linearsvc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"LinearSVC accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary module\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of the type GaussianNB\n",
    "gnb = GaussianNB()\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = gnb.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"GaussianNB accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create object of the type KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the algorithm\n",
    "neigh.fit(data_train, target_train)\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = neigh.predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"KNeighbors accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced Accuracy Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of the type SVC\n",
    "svc_model = SVC(random_state=0, class_weight='balanced')\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = svc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"SVC accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type DecisionTreeClassifier\n",
    "dtc_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = dtc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"DecisionTreeClassifier accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = rfc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print (\"RandomForestClassifier accuracy score: \",accuracy_score(target_test, pred))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Create an object of type LogisticRegression\n",
    "lr_model = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = lr_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"LogisticRegression accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary modules\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "#Create an object of type LinearSVC\n",
    "linearsvc_model = LinearSVC(random_state=0, class_weight='balanced')\n",
    "#Train the algorithm on training data and predict using the testing data\n",
    "pred = linearsvc_model.fit(data_train, target_train).predict(data_test)\n",
    "#Print the accuracy score of the model\n",
    "print(\"LinearSVC accuracy: \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"MicroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroRecall:\",recall_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MicroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='micro'))\n",
    "print(\"MacroPrecision:\",precision_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroRecall:\",recall_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"MacroF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='macro'))\n",
    "print(\"WeightedPrecision:\",precision_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedRecall:\",recall_score(target_test, pred, pos_label='positive', average='weighted'))\n",
    "print(\"WeightedF1_Score:\",f1_score(target_test, pred, pos_label='positive', average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
